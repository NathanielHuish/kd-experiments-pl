{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from src.dataset import CIFAR10DataModule\n",
    "from src.models import ModelFactory\n",
    "from pytorch_lightning.callbacks import ModelPruning\n",
    "from src.training_module import TrainingModule\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import pytorch_lightning as pl\n",
    "from src.prune_scheduler import AgpPruningRate\n",
    "import torchmetrics\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch\n",
    "from typing import Callable\n",
    "from pytorch_lightning.loggers.base import LightningLoggerBase\n",
    "import csv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class SparsityLogger(LightningLoggerBase):\n",
    "    def __init__(self, file_path, header=['epoch', 'layer', 'sparsity']):\n",
    "        super().__init__\n",
    "        self.file_path = file_path\n",
    "\n",
    "        with open(self.file_path, 'w') as f:\n",
    "          writer = csv.writer(f)\n",
    "          writer.writerow(header)\n",
    "    \n",
    "    def log(self, metrics):\n",
    "        fields = [metrics[\"epoch\"], metrics[\"layer\"], metrics[\"sparsity\"]]\n",
    "        filename = self.file_path\n",
    "        with open(filename, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(fields)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class PruningTrainingModule(TrainingModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name, \n",
    "        image_size, \n",
    "        num_classes, \n",
    "        lr, \n",
    "        momentum, \n",
    "        epochs,\n",
    "        weight_decay,\n",
    "        mixup,\n",
    "        pre_trained=False,\n",
    "    ):\n",
    "        super(TrainingModule, self).__init__()\n",
    "        self.lr = lr\n",
    "        self.image_size = image_size\n",
    "        self.num_classes = num_classes\n",
    "        self.weight_decay = weight_decay\n",
    "        self.momentum = momentum\n",
    "        self.epochs = epochs\n",
    "        self.mixup = mixup\n",
    "        self._model = self.create_model(model_name=model_name, pre_trained=pre_trained)\n",
    "        self._loss = nn.CrossEntropyLoss()\n",
    "        acc = torchmetrics.Accuracy()\n",
    "        self.val_acc = acc.clone()\n",
    "        self.train_acc = acc.clone()\n",
    "\n",
    "        self.freq = 1\n",
    "        self.prune_end = int(20 * 0.75)\n",
    "        self.prune_sch = AgpPruningRate(.05, .50, 1, self.prune_end, self.freq)\n",
    "        self.prune_layers = [module for module in self._model.modules()][:-1]\n",
    "\n",
    "    def on_train_epoch_start(self) -> None:\n",
    "        if self.current_epoch % self.freq == 1 and self.current_epoch <= self.prune_end:\n",
    "            target = self.prune_sch.step(self.current_epoch)\n",
    "            print(target)\n",
    "            print(f'pruning {target * 100}% sparsity')\n",
    "            if self.current_epoch > 1 and self.current_epoch < self.prune_end:\n",
    "                for i, layer in enumerate(self.prune_layers):\n",
    "                    if type(layer) == nn.Conv2d or type(layer) == nn.Linear:\n",
    "                        prune.remove(layer, \"weight\")\n",
    "            for i, layer in enumerate(self.prune_layers):\n",
    "                if type(layer) == nn.Conv2d or type(layer) == nn.Linear:\n",
    "                    prune.l1_unstructured(layer, name='weight', amount=float(target))\n",
    "                    layer_spar = float(torch.sum(layer.weight == 0))\n",
    "                    layer_spar /= float(layer.weight.nelement())\n",
    "                    print(f\"Sparsity in layer {i} {type(layer)} {layer_spar: 3f}\")\n",
    "        elif self.current_epoch > self.prune_end:\n",
    "            print(\"All done pruning\")\n",
    "\n",
    "    def OG_Pruning_Scheduler(self) -> Callable:\n",
    "        if self.current_epoch % self.freq == 1 and self.current_epoch <= self.prune_end:\n",
    "            target = self.prune_sch.step(self.current_epoch)\n",
    "            return target\n",
    "        else:\n",
    "            return 0\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class OG_Pruning_Callback(Callback):    \n",
    "    def on_train_epoch_start(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\n",
    "        if trainer.current_epoch % pl_module.freq == 1 and trainer.current_epoch <= pl_module.prune_end:\n",
    "            target = pl_module.prune_sch.step(trainer.current_epoch)\n",
    "            print(target)\n",
    "            print(f'pruning {target * 100}% sparsity')\n",
    "            if trainer.current_epoch > 1 and trainer.current_epoch < pl_module.prune_end:\n",
    "                for i, layer in enumerate(pl_module.prune_layers):\n",
    "                    if type(layer) == nn.Conv2d or type(layer) == nn.Linear:\n",
    "                        prune.remove(layer, \"weight\")\n",
    "            for i, layer in enumerate(pl_module.prune_layers):\n",
    "                if type(layer) == nn.Conv2d or type(layer) == nn.Linear:\n",
    "                    prune.l1_unstructured(layer, name='weight', amount=float(target))\n",
    "                    layer_spar = float(torch.sum(layer.weight == 0))\n",
    "                    layer_spar /= float(layer.weight.nelement())\n",
    "                    print(f\"Sparsity in layer {i} {type(layer)} {layer_spar: 3f}\")\n",
    "        elif trainer.current_epoch > pl_module.prune_end:\n",
    "            print(\"All done pruning\")\n",
    "    \n",
    "    def on_train_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\n",
    "        torch.save(trainer.model.state_dict(), 'og_pruning_weights.pth')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "training_module = PruningTrainingModule(\n",
    "    model_name='resnet34',\n",
    "    image_size=1,\n",
    "    num_classes=10,\n",
    "    pre_trained=False,\n",
    "    lr=0.01,\n",
    "    epochs=20,\n",
    "    mixup=False,\n",
    "    momentum=0.005,\n",
    "    weight_decay=1e-5\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dm = CIFAR10DataModule(data_dir='data/', num_workers=4, pin_memory=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "og_trainer = pl.Trainer(gpus=1, max_epochs=20, callbacks=[OG_Pruning_Callback()])\n",
    "\n",
    "og_trainer.fit(training_module, dm)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class PL_Pruning_Callback(Callback):\n",
    "   def on_train_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\n",
    "        torch.save(trainer.model.state_dict(), 'pl_pruning_weights.pth')\n",
    "\n",
    "pl_training_module = PruningTrainingModule(\n",
    "    model_name='resnet34',\n",
    "    image_size=1,\n",
    "    num_classes=10,\n",
    "    pre_trained=False,\n",
    "    lr=0.01,\n",
    "    epochs=20,\n",
    "    mixup=False,\n",
    "    momentum=0.005,\n",
    "    weight_decay=1e-5\n",
    "        )\n",
    "\n",
    "pl_pruning_trainer = pl.Trainer(gpus=1, max_epochs=20, callbacks=[PL_Pruning_Callback(), ModelPruning(pruning_fn=\"l1_unstructured\", parameter_names=[\"weight\"], prune_on_train_epoch_end=False, make_pruning_permanent=True, amount=pl_training_module.OG_Pruning_Scheduler(), apply_pruning=True, verbose=2)])\n",
    "\n",
    "pl_pruning_trainer.fit(pl_training_module ,dm)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('kd-experiments-pl': conda)"
  },
  "interpreter": {
   "hash": "f49cccf7948c7891734d7951c7101b50515718aed4b4bf7f2989b2296ea9cee9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}